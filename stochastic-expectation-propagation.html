<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>Stochastic Expectation Propagation | Dustin Tran</title>
	<meta name="description" content="  Yingzhen Li, Jose Miguel Hernandez-Lobato, and Richard E. Turner. Stochastic Expectation Propagation. In Neural Information Processing Systems, 2015.">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-Frame-Options" content="sameorigin">

	<!-- CSS -->
	<link rel="stylesheet" href="/blog/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/blog/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="http://dustintran.com/blog/stochastic-expectation-propagation">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="Dustin Tran" href="http://dustintran.com/blog/feed.xml" />

	<!-- Font Awesome -->
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
        <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
	

	<!-- Google Analytics -->
	
	<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-53150914-2', 'auto');
	ga('send', 'pageview');
	</script>
	
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/blog/">
			<img class="avatar" src="/blog/img/photo.png" alt=""/>
		</a>
		
		<h1 class="site-title">
			<a href="/blog/">Dustin Tran</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
                        <li>
				<a class="page-link" href="http://dustintran.com">
					about　
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled -->
			














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






		</ul>
	</nav>
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/blog/')">
    <h1 class="title">Stochastic Expectation Propagation</h1>
    <div style="padding-top:3%;"></div>
    <div class="meta">
      <span class="author">
        By
        
          <a class="author-name" href="http://dustintran.com">Dustin Tran</a>
        
      </span>
      <span class="date">Dec 6, 2015</span>
      <ul>
        














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






      </ul>
    </div>
  </header>
  <section class="post-content"><ul>
  <li>Yingzhen Li, Jose Miguel Hernandez-Lobato, and Richard E. Turner. Stochastic Expectation Propagation. In <em><a href="http://papers.nips.cc/paper/5760-stochastic-expectation-propagation.pdf">Neural Information Processing Systems</a></em>, 2015.</li>
</ul>

<h2 id="summary">Summary</h2>

<p>Expectation propagation (EP) is a popular technique for approximate Bayesian inference, although it has arguably lost favor in recent years to variational inference.  Whereas variational inference was made scalable to massive data sets through stochastic variational inference (Hoffman et al., 2013), and thus attractive to machine learning practitioners, expectation propagation is limited by a memory overhead which scales with the number of data points. This paper proposes an extension of EP which removes the complexity requirement and thus enables it to scale to massive data.</p>

<p>Let <script type="math/tex">\mathbf{x}=\{\mathbf{x}_k\}</script> be a data set split into <script type="math/tex">K</script> components, and <script type="math/tex">p(\mathbf{x}\mid\mathbf{\theta})</script> be a model likelihood with prior <script type="math/tex">p(\mathbf{\theta})</script>. We aim to learn an approximating distribution <script type="math/tex">q(\mathbf{\theta})</script> such that</p>

<script type="math/tex; mode=display">p(\mathbf{\theta}\mid \mathbf{x})
\propto
p(\mathbf{\theta})\prod_{k=1}^K p(\mathbf{x}_k\mid\mathbf{\theta})
\approx
q(\mathbf{\theta})
\propto
p(\mathbf{\theta})\prod_{k=1}^K f_k(\mathbf{\theta}).</script>

<p>Following the way Zoubin Ghahramani motivates EP, we would like to minimize <script type="math/tex">\mathrm{KL}(p(\mathbf{\theta}\mid \mathbf{x})\|q(\mathbf{\theta}))</script> (I have no clue who first motivated EP from this way—Zoubin’s slides were how I first learned this). This can be interpreted as a reverse analog of the variational objective: whereas VI is restricted to the support of the posterior and is “mode-seeking” (Minka, 2005), this KL contains <em>at least</em> the support of the posterior and is “inclusive” (Frey, 2000). Minimizing this KL could proceed by iteratively updating the factors <script type="math/tex">f_k(\mathbf{\theta})</script>. Denoting the leave-one-out posterior <script type="math/tex">p_{-k}(\mathbf{\theta})=p(\mathbf{\theta}\mid \mathbf{x})/p(\mathbf{x}_k\mid\mathbf{\theta})</script>, we iteratively minimize <script type="math/tex">\mathrm{KL}(p(\mathbf{\theta}\mid \mathbf{x})\|p_{-k}(\mathbf{\theta})f_k(\mathbf{\theta}))</script> for each <script type="math/tex">k=1,\ldots,K</script>.</p>

<p>However, <script type="math/tex">\mathrm{KL}(p\|q)</script> is intractable (and so is the iterative version) as it requires calculating the posterior density; therefore we minimize an approximation to it. Consider approximating the leave-one-out posterior with the <em>cavity distribution</em> <script type="math/tex">q_{-k}(\mathbf{\theta}) = q(\mathbf{\theta})/f_k(\mathbf{\theta})</script>, which is the approximating distribution without the <script type="math/tex">k^{th}</script> likelihood approximation. Define the <em>tilted distribution</em> <script type="math/tex">q_{\backslash k}(\mathbf{\theta})=q_{-k}(\mathbf{\theta}) p(\mathbf{x}_k\mid\mathbf{\theta})</script>, which is the corresponding cavity distribution with the true likelihood factor plugged in.  EP iteratively solves</p>

<script type="math/tex; mode=display">\min_{f_k}\mathrm{KL}(q_{\backslash k}(\mathbf{\theta}) \| q_{-k}(\mathbf{\theta}) f_k(\mathbf{\theta})),\quad k=1,\ldots,K.</script>

<p>This objective is a good proxy to <script type="math/tex">\mathrm{KL}(p\|q)</script> if the true likelihood factor <script type="math/tex">p(\mathbf{x}_k\mid\mathbf{\theta})</script> contributes to the leave-one-out posterior in the same way as it does in the tilted distribution.</p>

<p>Calculating the cavity distribution for each <script type="math/tex">k</script> requires explicit storage of the approximating factors <script type="math/tex">f_k(\mathbf{\theta})</script>. This implies that EP has an <script type="math/tex">\mathcal{O}(K)</script> memory requirement which prevents it from scaling to large data sets. To solve this, the authors consider storage of only a single factor <script type="math/tex">f(\mathbf{\theta})</script>; rather than trying to capture the individual effect of the likelihood factors, the single factor captures only the average effect. Stochastic expectation propagation (SEP) uses the same iterative KL objective to learn the next approximating factor <script type="math/tex">f_k(\mathbf{\theta})</script>, and additionally updates <script type="math/tex">f(\mathbf{\theta})=f(\mathbf{\theta})^{1-1/K}f_k(\mathbf{\theta})^{1/K}</script>.  By storing only the average effect of the likelihood factors, SEP approximates the true cavity distributions <script type="math/tex">q_{-k}(\mathbf{\theta})\propto q(\mathbf{\theta})/f_k(\mathbf{\theta})</script> with an averaged cavity distribution <script type="math/tex">q_{-1}(\mathbf{\theta})\propto q(\mathbf{\theta})/f(\mathbf{\theta})</script>.</p>

<h2 id="discussion">Discussion</h2>

<p>I’m a big fan of the paper. The exposition on EP, assumed density filtering, and message passing is excellent, and it naturally motivates SEP following the technical developments of EP. The use of an averaged cavity distribution is an unfortunate compromise, but it seems necessary in order to scale local approximation techniques such as EP.</p>

<p>The authors make a cool connection to SVI. If the local minimizations in SEP are instead doing the reverse KL, then this is a form of “stochastic” variational message passing. Moreover, if the update for the single factor <script type="math/tex">f(\mathbf{\theta})</script> follows <script type="math/tex">f(\mathbf{\theta})^{1 - \epsilon}f_n(\mathbf{\theta})^{\epsilon}</script> where <script type="math/tex">\epsilon</script> uses a Robbins-Monro schedule, then this is the same as stochastic variational inference with a mean-field approximation. An interesting extension then is to apply the equivalent of an adaptive learning rate in stochastic approximations for the geometric scale factor when updating <script type="math/tex">f(\mathbf{\theta})</script>.</p>

<p>Hogwild (Nui et al., 2011) and asynchronous versions also naturally follow which is cool. I also think it would have been useful for the paper to fight for the streaming data stance. That is, it’s trivial for stochastic EP to learn on streaming data whereas it is impossible for vanilla EP.</p>

<p>The move to <script type="math/tex">\mathrm{KL}(p\|q)</script> with SEP does require some compromises in contrast to SVI unfortunately. For instance, unlike VI to SVI, EP to SEP compromises the approximation quality in order to make it scalable. That is, SVI still performs the same global minimization of <script type="math/tex">\mathrm{KL}(q\|p)</script>, and shares nice properties through theory of stochastic approximations (Robbins and Monro, 1951), whereas SEP does not preserve the same local minimization as EP. You can imagine scenarios where an averaged likelihood approximator will not work, or even the “minibatch” M of K extension of them. Additionally, it’s not immediately clear how to extend EP beyond approximations which preserve dependence between the local approximations.</p>

<p>Minor comment: like much of Tom Minka’s work, they note that the local KL minimizations can more generally use <script type="math/tex">\alpha</script>-divergence measures. I still think this is a little restricting, as in general you just want <em>some</em> approximation; therefore something like a Laplace approximation (Smola et al., 2004) is valid as well, and similarly, nested EP (Riihimaki et al., 2013) is more conducive following this motivation.</p>

<p>I’m excited to hear more about stochastic EP from their poster and spotlight at NIPS! (The same authors have a number of interesting extensions of this paper at a few workshops as well.)</p>
</section>
</article>

<!-- Post navigation -->


<!-- Disqus -->


    </div>
    
<script src="/blog/js/katex_init.js"></script>



<footer class="site-footer">
	<p class="text">© 2016 ・ <a class="plain" href="http://dustintran.com">dustintran.com</a>
</p>
</footer>


  </body>
</html>
