<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>Denoising Criterion for Variational Auto-Encoding Framework | Dustin Tran</title>
	<meta name="description" content="  Daniel Jiwoong Im, Sungjin Ahn, Roland Memisevic, and Yoshua Bengio. Denoising Criterion for Variational Auto-Encoding Framework. arXiv preprint arXiv:1511...">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-Frame-Options" content="sameorigin">

	<!-- CSS -->
	<link rel="stylesheet" href="/blog/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/blog/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="http://dustintran.com/blog/denoising-criterion-for-variational-auto-encoding-framework">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="Dustin Tran" href="http://dustintran.com/blog/feed.xml" />

	<!-- Font Awesome -->
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
        <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
	

	<!-- Google Analytics -->
	
	<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-53150914-2', 'auto');
	ga('send', 'pageview');
	</script>
	
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/blog/">
			<img class="avatar" src="/blog/img/photo.png" alt=""/>
		</a>
		
		<h1 class="site-title">
			<a href="/blog/">Dustin Tran</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
                        <li>
				<a class="page-link" href="http://dustintran.com">
					about　
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled -->
			














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






		</ul>
	</nav>
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/blog/')">
    <h1 class="title">Denoising Criterion for Variational Auto-Encoding Framework</h1>
    <div style="padding-top:3%;"></div>
    <div class="meta">
      <span class="author">
        By
        
          <a class="author-name" href="http://dustintran.com">Dustin Tran</a>
        
      </span>
      <span class="date">Dec 1, 2015</span>
      <ul>
        














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






      </ul>
    </div>
  </header>
  <section class="post-content"><ul>
  <li>Daniel Jiwoong Im, Sungjin Ahn, Roland Memisevic, and Yoshua Bengio. Denoising Criterion for Variational Auto-Encoding Framework. <a href="http://arxiv.org/abs/1511.06406">arXiv preprint arXiv:1511.06406</a>, 2015.</li>
</ul>

<h2 id="summary">Summary</h2>

<p>Auto-encoders are used to learn representations of observed data <script type="math/tex">x</script>. They do so by minimizing the reconstruction error of a decoder <script type="math/tex">p(x\mid z)</script>, given a characterization of hidden variables <script type="math/tex">z</script> from an encoder <script type="math/tex">q(z\mid x)</script>. Along with a penalty <script type="math/tex">P_\alpha</script> for regularization, this can be written as maximizing the objective</p>

<script type="math/tex; mode=display">\mathcal{L}_{\text{ae}} = \mathbb{E}_{q(z\mid x)}[\log p(x\mid z)] - P_\alpha</script>

<p>over the encoder and decoder’s parameters. However, it’s unclear what a principled choice of the penalty is, as well as the choice of the encoder for a given decoder <script type="math/tex">p(x\mid z)</script>. Variational auto-encoders (Kingma and Welling, 2014; Rezende et al., 2014) reinterpret the evidence lower bound prominent in variational inference for this purpose:</p>

<script type="math/tex; mode=display">\mathcal{L}_{\text{vae}} = \mathbb{E}_{q(z\mid x)}[\log p(x\mid z)] - \mathrm{KL}(q(z\mid x)\| p(z)),</script>

<p>where <script type="math/tex">p(z)</script> is a model prior placed over the hidden variables of the encoder. The penalty term is automatically given as the KL divergence between the encoder and the prior, and the encoder can more generally be specified following variational inference literature. This is now a probabilistic encoder-decoder, with a principled objective given by a lower bound to the model evidence <script type="math/tex">\log p(x)</script>.</p>

<p>In this paper, Im et al. take ideas from denoising auto-encoders (Vincent et al., 2008) and apply it to variational auto-encoders. In particular, they consider a <em>corrupted distribution</em> <script type="math/tex">q(x'\mid x)</script>, such that</p>

<script type="math/tex; mode=display">q(z\mid x) = \int q(z\mid \tilde{x})q(\tilde{x}\mid x)\mathrm{d}\tilde{x}.</script>

<p>With a distribution to model corrupted noise, the augmented <script type="math/tex">q(z\mid x)</script> is more expressive than the original <script type="math/tex">q(z\mid x)</script> without corruption: it is able to model additional uncertainty around the data inputs.</p>

<p>For inference, plugging this variational distribution into the ELBO leads to an analytically intractable objective, as the log-density <script type="math/tex">\log q(z\mid x)</script> cannot be computed. As a proxy, they propose maximizing the objective function</p>

<script type="math/tex; mode=display">\mathcal{L}_{\text{dvae}} = \mathbb{E}_{q(\tilde{x}\mid x)}\Big[\mathbb{E}_{q(z\mid x)}\Big[\log\frac{p(x, z)}{q(z\mid\tilde{x})}\Big]\Big],</script>

<p>which they show is in fact an upper bound to the original ELBO. They also claim it is still a lower bound to the model evidence <script type="math/tex">\log p(x)</script>, and thus still a valid variational objective (I’ll comment on this later). Gradients proceed as typically done in the literature, either using the reparameterized gradient for differentiable latent variables, or the score function estimator in the more general case. They have an interesting Q&amp;A format for discussing their experiments that I found kind of cool.</p>

<h2 id="discussion">Discussion</h2>

<p>This paper is eerily similar to a paper Rajesh Ranganath, Dave Blei, and I uploaded just two weeks earlier than theirs, on <a href="http://arxiv.org/abs/1511.02386">Hierarchical Variational Models</a>. And that was uploaded only three weeks ago from today! Man, the field moves fast.</p>

<ul>
  <li>The idea is the same: place a prior on inputs to the variational distribution—treating them as <em>variational</em> latent variables—and proceed to marginalize them out. The new inputs are now the inputs to the prior distribution. In their case, the prior is on the data input for inference networks, which output local variational parameters. In our case, the prior is on variational parameters more generally. A prior on data input is the special case when the variational model uses an inference network: following our notation, we replace  <script type="math/tex">q(z;\lambda)</script> with the more powerful <script type="math/tex">q(z;\theta)=\int q(z\mid\lambda)q(\lambda;\theta)\mathrm{d}\lambda</script>, and use an inference network <script type="math/tex">\phi</script> to output prior hyperparameters <script type="math/tex">\theta=\phi(x)</script> (see end of Section 5).</li>
  <li>The source of inspiration is different: they follow the standard procedure in denoising auto-encoders. We follow the Bayesian framework, viewing the variational distribution as a model of the posterior latent variables. These different sources of inspiration motivate difference choices of complexity for the prior: they only consider Bernoulli or Gaussian, whereas from the Bayesian interpretation, it is natural to study more complex priors such as the normalizing flow (Rezende and Mohamed, 2015) as a prior; we show the latter leads to more expressive approximations and also more scalable computation. (And in our more recent paper on the <a href="http://arxiv.org/abs/1511.06499">Variational Gaussian Process</a>, we use an even cooler prior :^).</li>
  <li>The variational objectives are different, and I have concerns that their objective is not in fact a lower bound on <script type="math/tex">\log p(x)</script>.¹ This means the values of the objective function are no longer a proxy for the model evidence. Among a few things, this invalidates the experimental results, as they compare to methods based on reported variational bounds. Further, maximizing their objective can lead to poor approximations, as there is no stopping the function to blow up to arbitrary values as the global maximum. Actually, it surprises me that the maximized variational objective values in the experiments are still close to those in <script type="math/tex">\mathcal{L}_{\text{vae}}</script>. Would be very interested to hear from the authors on these issues.</li>
</ul>

<p>Regardless of whether the theorems and experiments are correct, denoising variational auto-encoders is a much needed idea. It provides great intuition for why one should use hierarchical instantiations of variational models. Moreover it’s always interesting to see the same ideas inspired from a different field. These intuitions especially go nicely with our <a href="http://arxiv.org/abs/1511.06499">VGP paper</a>, in which we make more explicit the auto-encoder connection for learning variational models with latent variables. Maybe we’ll add these details in a future revision.</p>

<p>Minor point: They claim that injecting noise both at the data input level (“denoising auto-encoder”) and the stochastic hidden layer level (“variational auto-encoder”) can be advantageous. However, they’re really one and the same, which I’m sure they’re aware of as they wrote Lemma 1 in this light. That is, the corrupted hidden variable <script type="math/tex">\tilde{x}</script> is just another stochastic hidden layer, which is marginalized out. This makes the abstract and introduction a little confusing.</p>

<p>¹ In the proof of Lemma 1, when they try to show that <script type="math/tex">\log p(x)</script> upper bounds <script type="math/tex">\mathcal{L}_{\text{dvae}}</script>, there are three expectations expanded out in the first line. If the two expectations regarding the distribution <script type="math/tex">q(z'\mid x)</script> are more explicitly written, it is clear why the <script type="math/tex">q</script>’s do not necessarily cancel:</p>

<script type="math/tex; mode=display">\mathbb{E}_{q_{\psi}(z''\mid x)}
\mathbb{E}_{q_{\psi}(z'\mid x)}
\Big[
\log
\mathbb{E}_{q_{\varphi}(z\mid z'')}
\Big[
\frac{p_\theta(x,z)}{q_{\varphi}(z\mid z')}
\Big]
\Big]
\ne
\mathbb{E}_{q_{\psi}(z''\mid x)}
\mathbb{E}_{q_{\psi}(z'\mid x)}
[
\log
p_\theta(x)].</script>

<p>When discussing this with Rajesh Ranganath, he points out a simple counterexample where <script type="math/tex">\mathcal{L}_{\text{dvae}}>\log p(x)</script>: Consider a one-dimensional latent variable model, with <script type="math/tex">p(x,z)=\mathrm{Bernoulli}(z;0.5)</script>. Let</p>

<script type="math/tex; mode=display">q(\tilde{x}\mid x) = \mathrm{Bernoulli}(\tilde{x}; 0.5),~
q(z=1\mid \tilde{x}=1) = 0.1,~
q(z=1\mid \tilde{x}=0) = 0.9.</script>

<p>Then <script type="math/tex">q(z\mid x)</script> is Bernoulli with probability <script type="math/tex">0.5\cdot0.1+0.5\cdot0.9=0.5</script>, and</p>

<script type="math/tex; mode=display">\mathcal{L}_{\text{dvae}} =
\mathbb{E}_{q(\tilde{x}\mid x)}\Big[\mathbb{E}_{q(z\mid x)}\Big[\log\frac{p(x, z)}{q(z\mid\tilde{x})}\Big]\Big]</script>

<script type="math/tex; mode=display">= \mathbb{E}_{q(\tilde{x}\mid x)}\Big[0.5\log\frac{0.5}{q(z=1\mid\tilde{x})}+0.5\log\frac{0.5}{q(z=0\mid\tilde{x})}\Big]</script>

<script type="math/tex; mode=display">= 0.5\Big[0.5\log\frac{0.5}{0.1}+0.5\log\frac{0.5}{0.9}\Big]
+
0.5\Big[0.5\log\frac{0.5}{0.9}+0.5\log\frac{0.5}{0.1}\Big]</script>

<script type="math/tex; mode=display">=0.510826...</script>

<p>But <script type="math/tex">\log p(x)=0</script>, implying <script type="math/tex">\mathcal{L}_{\text{dvae}}>\log p(x)</script>. In fact, taking 0.9 in the variational parameter to be arbitrarily close to 1 makes <script type="math/tex">\mathcal{L}_{\text{dvae}}</script> explode.</p>
</section>
</article>

<!-- Post navigation -->


<!-- Disqus -->


    </div>
    
<script src="/blog/js/katex_init.js"></script>



<footer class="site-footer">
	<p class="text">© 2016 ・ <a class="plain" href="http://dustintran.com">dustintran.com</a>
</p>
</footer>


  </body>
</html>
