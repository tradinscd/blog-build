<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>A Research to Engineering Workflow | Dustin Tran</title>
	<meta name="description" content="Going from a research idea to experiments is fundamental. But thisstep is typically glossed over with little explicit advice. Inacademia, the graduate studen...">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-Frame-Options" content="sameorigin">

	<!-- CSS -->
	<link rel="stylesheet" href="/blog/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/blog/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="http://dustintran.com/blog/a-research-to-engineering-workflow">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="Dustin Tran" href="http://dustintran.com/blog/feed.xml" />

	<!-- Font Awesome -->
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
        <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
	

	<!-- Google Analytics -->
	
	<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-53150914-2', 'auto');
	ga('send', 'pageview');
	</script>
	
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/blog/">
			<img class="avatar" src="/blog/img/photo.png" alt=""/>
		</a>
		
		<h1 class="site-title">
			<a href="/blog/">Dustin Tran</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
                        <li>
				<a class="page-link" href="http://dustintran.com">
					about　
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled -->
			














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






		</ul>
	</nav>
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/blog/')">
    <h1 class="title">A Research to Engineering Workflow</h1>
    <div style="padding-top:3%;"></div>
    <div class="meta">
      <span class="author">
        By
        
          <a class="author-name" href="http://dustintran.com">Dustin Tran</a>
        
      </span>
      <span class="date">Jun 3, 2017</span>
      <ul>
        














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






      </ul>
    </div>
  </header>
  <section class="post-content"><p>Going from a research idea to experiments is fundamental. But this
step is typically glossed over with little explicit advice. In
academia, the graduate student is often left toiling away—fragmented
code, various notes and LaTeX write-ups scattered around.
New projects often result in entirely new code bases, and if they do
rely on past code, are difficult to properly extend to these new projects.</p>

<p>Motivated by this, I thought it’d be useful to outline the steps I
personally take in going from research idea to experimentation, and
how that then improves my research understanding so I can revise the
idea. This process is crucial: given an initial idea, all my time is
spent on this process;
<!--(with the majority of my time specifically spent on the experiments)-->
and for me at least, the experiments are key to
learning about and solving problems that I couldn’t predict otherwise.<a href="#references"><sup>1</sup></a>
<!--More generally, I think without having a good                         -->
<!--handle on this process, you can sometimes lose touch with             -->
<!--reality and have a hard time                                          -->
<!--[>figuring out what open problems and/or solutions are important.<]   -->
<!--recalling why the problems you're working on are important.           --></p>

<!--Much of what I'll describe is what other researchers, collaborators,-->
<!--and friends I know already do. I'm hoping to make these steps       -->
<!--transparent, we can review the workflow, compare it to alternatives,-->
<!--and see how it might be optimized.                                  -->

<!--## Coming up with an Idea-->
<h2 id="finding-the-right-problem">Finding the Right Problem</h2>
<!--## A Master List of Research Ideas-->

<!--+ reading papers                                                      -->
<!--+ talking to people at conferences, workshops, etc. to see what find  -->
<!--  important                                                           -->
<!--+ personal experiences (in both research/understanding and in your own-->
<!--  experiments)                                                        -->
<!--+ frequent communication with people near you, if you have the benefit-->
<!--  of like minded(or even not like minded) people as neighbors to      -->
<!--  bounce ideas off of                                                 -->

<!--This is the modt open ended and often in my opinion one of the most-->
<!--challenging. It must be interesting to you, ideally ambitious with -->
<!--clear and amazing end goals, important to many people in the       -->
<!--community, and with short and long term visions.                   -->

<!--Research is an organic process. Repositories file that research in-->
<!--discrete units. Before making a repository, it's necessary to     -->
<!--decide how initial ideas might jumpstart into more official and   -->
<!--formalized.                                                       -->

<!--This particular step varies widely. -->
<p>Before working on a project, it’s necessary to decide how
ideas might jumpstart into something more official. Sometimes it’s as
simple as having a mentor suggest a project to work on; or tackling a
specific data set or applied problem; or having a conversation with a
frequent collaborator and then striking up a useful problem
to work on together. More often, I find that research is
a result of a long chain of ideas which were continually
iterated upon—through frequent conversations, recent
work, longer term readings of subjects I’m unfamiliar with
(e.g., <a class="citation" href="#pearl2000causality">Pearl (2000)</a>),
and
favorite papers I like to revisit (e.g.,
<a class="citation" href="#wainwright2008graphical">Wainwright &amp; Jordan (2008)</a>,
<a class="citation" href="#neal1994bayesian">Neal (1994)</a>).</p>

<p><img src="/blog/assets/2017-06-03-fig0.png" alt="" />
<em><center>A master document of all my unexplored research ideas.</center></em></p>

<p>One technique I’ve found immensely helpful is to maintain a single
master document.<a href="#references"><sup>2</sup></a>
It does a few things.</p>

<p>First, it has a bulleted list of all ideas, problems, and topics that
I’d like to think more carefully about (Section 1.3 in the figure).
Sometimes they’re as high-level as “Bayesian/generative approaches to
reinforcement learning” or “addressing fairness in machine learning”;
or they’re as specific as “Inference networks to handle memory
complexity in EP” or “analysis of size-biased vs symmetric Dirichlet
priors.”.  I try to keep the list succinct: subsequent sections go in
depth on a particular entry (Section 2+ in the figure).</p>

<p>Second, the list of ideas is sorted according to what I’d like to work on
next. This guides me to understand the general direction of my
research beyond present work. I can continually revise my
priorities according to whether I think the direction aligns
with my broader research vision, and if I think the direction is
necessarily impactful for the community at large.
<!-- -->
Importantly, the list isn’t just about the next publishable idea to
work on, but generally what things I’d like to learn about next. This
contributes long-term in finding important problems and arriving at
simple or novel solutions.</p>

<p>Every so often, I revisit the list, resorting things, adding things,
deleting things. Eventually I might elaborate upon an idea enough that
it becomes a formal paper. In general, I’ve found that this process
of iterating upon ideas within one location (and one format) makes
the transition to formal paper-writing and experiments to be a fluid experience.</p>

<h2 id="managing-papers">Managing Papers</h2>

<p><img src="/blog/assets/2017-06-03-fig5.png" alt="" /></p>

<p>Good research requires reading <em>a lot</em> of papers. Without a good way
of organizing your readings, you can easily get overwhelmed by the
field’s hurried pace. (These past
weeks have been especially notorious in trying to catch up on the slew
of NIPS submissions posted to arXiv.)</p>

<p>I’ve experimented with a lot of approaches to this, and ultimately
I’ve arrived at the <a href="http://papersapp.com">Papers app</a> which I highly
recommend.<sup>3</sup></p>

<p>The most fundamental utility in a good management system is a
centralized repository which can be referenced back to. The advantage
of having one location for this cannot be underestimated, whether it
be 8 page conference papers, journal papers, surveys, or even textbooks.
Moreover, Papers is a nice tool for actually reading PDFs, and it
conveniently syncs across devices as I read and star things on my
tablet or laptop.  As I cite papers when I write, I can go back to
Papers and get the corresponding BibTeX file and citekey.</p>

<p>I personally enjoy taking painstaking effort in organizing papers. In
the screenshot above, I have a sprawling list of topics as paper tags.
These range from <code class="highlighter-rouge">applications</code>, <code class="highlighter-rouge">models</code>, <code class="highlighter-rouge">inference</code> (each with
subtags), and there are also miscellaneous topics such as
<code class="highlighter-rouge">information-theory</code> and <code class="highlighter-rouge">experimental-design</code>. An important
collection not seen in the screenshot is a tag called <code class="highlighter-rouge">research</code>,
which I bin all papers relevant to a particular research topic into.
For example, <a href="https://arxiv.org/abs/1706.00531">the PixelGAN paper</a>
presently highlighted is tagged into two topics I’ve currently been
thinking a lot about—these are sorted into <code class="highlighter-rouge">research→alignment-semi</code>
and <code class="highlighter-rouge">research→generative-images</code>.</p>

<h2 id="managing-a-project">Managing a Project</h2>

<p><img src="/blog/assets/2017-06-03-fig1.png" alt="" />
<em><center>The repository we used for a recent
<a href="https://arxiv.org/abs/1610.09037">arXiv preprint</a>.</center></em></p>

<p>I like to maintain one research project in one Github repository.
<!--Whatever one "unit" of research is varies. I define it as something   -->
<!--relatively self-contained; for example, it might be tied to a specific-->
<!--paper, an applied data analysis, or a particular topic at hand.       -->
<!-- -->
They’re useful not only for tracking code but also
in tracking general research progress, paper writing, and tying others
in for collaboration. How Github repositories are organized is a frequent pain point.
I like the following structure,
based originally from <a href="http://www.cs.columbia.edu/~blei/seminar/2016_discrete_data/notes/week_01.pdf">Dave Blei’s preferred one</a>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-- doc/
  -- 2017-nips/
    -- preamble/
    -- img/
    -- main.pdf
    -- main.tex
    -- introduction.tex
-- etc/
  -- 2017-03-25-whiteboard.jpg
  -- 2017-04-03-whiteboard.jpg
  -- 2017-04-06-dustin-comments.md
  -- 2017-04-08-dave-comments.pdf
-- src/
  -- checkpoints/
  -- codebase/
  -- log/
  -- out/
  -- script1.py
  -- script2.py
-- README.md
</code></pre></div></div>

<p><code class="highlighter-rouge">README.md</code> maintains a list of todo’s, both for myself and
collaborators. This makes it transparent how to keep moving forward
and what’s blocking the work.</p>

<p><code class="highlighter-rouge">doc/</code> contains all write-ups. Each subdirectory corresponds to a
particular conference or journal submission, with <code class="highlighter-rouge">main.tex</code> being the
primary document and individual sections written in separate files
such as <code class="highlighter-rouge">introduction.tex</code>. Keeping one section per file makes
it easy for multiple people to work on separate sections
simultaneously and avoid merge conflicts. Some people prefer to write
the full paper after major experiments are complete. I personally like to
write a paper more as a summary of the current ideas and, as with the
idea itself, it is continually revised as experiments proceed.</p>

<p><code class="highlighter-rouge">etc/</code> is a dump of everything not relevant to other directories. I
typically use it to store pictures of whiteboards during conversations
about the project. Or sometimes as I’m just going about my day-to-day,
I’m struck with a bunch of ideas and so I dump them into a Markdown
document. It’s also a convenient location to handle various
commentaries about the work, such as general feedback or paper
markups from collaborators.</p>

<p><code class="highlighter-rouge">src/</code> is where all code is written. Runnable scripts are written
directly in <code class="highlighter-rouge">src/</code>, and classes and utilities are written in
<code class="highlighter-rouge">codebase/</code>. I’ll elaborate on these next. (The other three are
directories outputted from scripts, which I’ll also elaborate upon.)</p>

<h2 id="writing-code">Writing Code</h2>

<p><img src="/blog/assets/2017-06-03-fig2.png" alt="" />
<!--_<center>A master document of all my unexplored research ideas.</center>_--></p>

<p>Any code I write now uses <a href="http://edwardlib.org">Edward</a>.
<!--which uses                                                                    -->
<!--[Python](https://www.python.org) and [TensorFlow](https://www.tensorflow.org).-->
I find it to be the best framework for
quickly experimenting with modern probabilistic models and algorithms.
<!--[<sup>3</sup>](#references)-->
<!--developing modern probabilistic models and inference algorithms.-->
<!--, and with plug-and-play with built-in methods and pre-existing examples.-->
<!-- -->
<!--Previously I had to resort to working in fragmented code bases, where -->
<!--one language had one idea, a pre-existing code base was hacked upon to-->
<!--support certain other features, additional interface layers were      -->
<!--written to get them all to communicate together... it was not good.   -->
<!--Maintaining these dependencies and duplicate implemented ideas is a  -->
<!--nightmare. And more importantly the code just constrains the sorts of-->
<!--ideas/experiments you'd like to do.                                  -->
<!--With Edward, everything is just there™. --></p>

<p>On a conceptual level, Edward’s
appealing because the language explicitly follows the math: the
model’s generative process translates to specific lines of Edward
code; then the proposed algorithm translates to the next lines; etc. This
clean translation
<!--makes it easy to understand the mapping between math-->
<!--and code. And it                                    -->
avoids future abstraction headaches when trying to extend the
code with natural research questions: for example, what if I used a different
prior, or tweaked the gradient estimator, or tried a different
neural net architecture, or applied the method on larger scale data sets?
<!-- which makes it easy to translate engineering   -->
<!--ideas about sharing various components to the math, and analogously   -->
<!--how to easily take tweaked math ideas and replace the corresponding   -->
<!--code.                                                                 --></p>

<p>On a practical level, I most benefit from Edward by building off
pre-existing model examples
(in <a href="https://github.com/blei-lab/edward/tree/master/examples"><code class="highlighter-rouge">edward/examples/</code></a> or <a href="https://github.com/blei-lab/edward/tree/master/notebooks"><code class="highlighter-rouge">edward/notebooks/</code></a>),
and then adapting it to my problem.
If I am also implementing a new
algorithm, I take a pre-existing algorithm’s source
code (in <a href="https://github.com/blei-lab/edward/tree/master/edward/inferences"><code class="highlighter-rouge">edward/inferences/</code></a>),
paste it as a new file in my research project’s <code class="highlighter-rouge">codebase/</code> directory,
and then I tweak it. This process makes it really easy to start
afresh—beginning from templates and avoiding low-level details.</p>

<p>When writing code, I always follow PEP8 (I particularly like the
<a href="https://pypi.python.org/pypi/pep8"><code class="highlighter-rouge">pep8</code></a> package), and I try
to separate individual scripts from the class and function definitions shared
across scripts; the latter is placed inside <code class="highlighter-rouge">codebase/</code> and then imported.
Maintaining code quality from the beginning is always a good
investment, and I find this process scales well as the code gets
increasingly more complicated and worked on with others.</p>

<p><strong>On Jupyter notebooks.</strong>
Many people use <a href="http://jupyter.org">Jupyter notebooks</a>
as a method for interactive code development, and as an easy way to
embed visualizations and LaTeX. I personally haven’t found
success in integrating it into my workflow. I like to just write all
my code down in a Python script and then run the script. But I can see why
others like the interactivity.</p>

<h2 id="managing-experiments">Managing Experiments</h2>

<p><img src="/blog/assets/2017-06-03-fig3.png" alt="" /></p>

<p>Investing in a good workstation or cloud service is a must.
Features such as GPUs should basically
be a given with <a href="http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/">their wide
availability</a>,
and one should have access to running many jobs in parallel.</p>

<p>After I finish writing a script on my local computer, my typical workflow is:</p>

<ol>
  <li>Run <code class="highlighter-rouge">rsync</code> to synchronize my local computer’s Github repository
  (which includes uncommitted files) with a directory in the server;</li>
  <li><code class="highlighter-rouge">ssh</code> into the server.</li>
  <li>Start <code class="highlighter-rouge">tmux</code> and run the script. Among many things, <code class="highlighter-rouge">tmux</code> lets you
detach the session so you don’t have to wait for the job to finish
before interacting with the server again.</li>
</ol>

<p>When the script is sensible, I start diving into experiments with
multiple hyperparameter configurations.
A useful tool for this is
<a href="https://docs.python.org/3/library/argparse.html"><code class="highlighter-rouge">argparse</code></a>.
It augments a Python script with commandline arguments, where you
add something like the following to your script:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--batch_size'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s">'Minibatch during training'</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">'--lr'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s">'Learning rate step-size'</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">lr</span>
</code></pre></div></div>
<p>Then you can run terminal commands such as</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python script1.py <span class="nt">--batch_size</span><span class="o">=</span>256 <span class="nt">--lr</span><span class="o">=</span>1e-4
</code></pre></div></div>
<p>This makes it easy to submit server jobs which vary these hyperparameters.</p>

<p>Finally, let’s talk about managing the output of experiments.
Recall the <code class="highlighter-rouge">src/</code> directory structure above:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-- src/
  -- checkpoints/
  -- codebase/
  -- log/
  -- out/
  -- script1.py
  -- script2.py
</code></pre></div></div>
<p>We described the individual scripts and <code class="highlighter-rouge">codebase/</code>.
The other three directories are for organizing experiment output:</p>

<ul>
  <li><code class="highlighter-rouge">checkpoints/</code> records saved model parameters during training.
Use <code class="highlighter-rouge">tf.train.Saver</code> to save parameters as the algorithm runs every
fixed number of iterations. This helps with running long experiments, where you
might want to cut the experiment short and later restore the
parameters. Each experiment outputs a subdirectory in <code class="highlighter-rouge">checkpoints/</code>
with the convention,
<code class="highlighter-rouge">20170524_192314_batch_size_25_lr_1e-4/</code>. The first
number is the date (<code class="highlighter-rouge">YYYYMMDD</code>); the second is the timestamp (<code class="highlighter-rouge">%H%M%S</code>);
and the rest is hyperparameters.</li>
  <li><code class="highlighter-rouge">log/</code> records logs for visualizing learning.
Each experiment belongs in a subdirectory with the same
convention as <code class="highlighter-rouge">checkpoints/</code>.
One benefit of Edward is that for logging, you can simply pass an
argument as <code class="highlighter-rouge">inference.initialize(logdir='log/' + subdir)</code>.
Default TensorFlow summaries are tracked which can then be
visualized using TensorBoard (more on this next).</li>
  <li><code class="highlighter-rouge">out/</code> records exploratory output after training finishes; for example,
generated images or matplotlib plots.
Each experiment belongs in a subdirectory with the same convention
as <code class="highlighter-rouge">checkpoints/</code>.</li>
</ul>

<p><strong>On data sets.</strong>
Data sets are used across many research projects. I prefer storing them
in the home directory <code class="highlighter-rouge">~/data</code>.</p>

<p><strong>On software containers.</strong>
<a href="http://python-guide-pt-br.readthedocs.io/en/latest/dev/virtualenvs/">virtualenv</a>
is a must for managing Python dependencies and avoiding difficulties
with system-wide Python installs. It’s particularly nice if you like
to write Python 2/3-agnostic code.
<a href="https://www.docker.com">Docker containers</a> are an even more powerful
tool if you require more from your setup.</p>

<h2 id="exploration-debugging--diagnostics">Exploration, Debugging, &amp; Diagnostics</h2>

<p><img src="/blog/assets/2017-06-03-fig4.png" alt="" />
<!--_<center>Picture thanks to                                                   -->
<!--<a href="https://github.com/blei-lab/edward/pull/653#issuecomment-304728311">-->
<!--Sean Kruzel</a>.</center>_                                                   --></p>

<p><a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard">Tensorboard</a>
is an excellent tool for visualizing and exploring your model
training. With TensorBoard’s interactivity, I find it
particularly convenient in that I don’t have to configure a bunch of
matplotlib functions to understand training. One only needs to percolate a
bunch of <code class="highlighter-rouge">tf.summary</code>s on tensors in the code.</p>

<p>Edward logs a bunch of summaries by default in order to visualize how
loss function values, gradients, and parameter change across
training iteration.
TensorBoard also includes wall time comparisons, and
a sufficiently decorated TensorFlow code base provides a nice
computational graph you can stare at.
For nuanced issues I can’t diagnose with TensorBoard specifically, I
just output things in the <code class="highlighter-rouge">out/</code> directory and inspect those results.</p>

<p><strong>Debugging error messages.</strong>
My debugging workflow is terrible. I
percolate print statements across my code and
find errors by
process of
elimination. This is primitive. Although I haven’t tried it, I
hear good things about
<a href="https://www.tensorflow.org/programmers_guide/debugger">TensorFlow’s debugger</a>.</p>

<h2 id="improving-research-understanding">Improving Research Understanding</h2>

<p>Interrogating your model, algorithm, and generally the learning
process lets you better understand your work’s success and failure
modes. This lets you go back to the drawing board, thinking deeply
about the method and how it might be further improved.
As the method indicates success, one can go
from tackling simple toy configurations to increasingly large
scale and high-dimensional problems.</p>

<p>From a higher level, this workflow is really about implementing the
scientific method in the real world.  No major ideas are necessarily
discarded at each iteration of the experimental process, but rather,
as in the ideal of science, you start with fundamentals and
iteratively expand upon them as you have a stronger grasp of reality.</p>

<p>Experiments aren’t alone in this process either. Collaboration,
communicating with experts from other fields, reading papers, working
on both short and longer term ideas, and attending talks and
conferences help broaden your perspective in finding the right
problems and solving them.</p>

<h2 id="footnotes--references">Footnotes &amp; References</h2>

<p><sup>1</sup> This workflow is specifically for empirical research.
Theory is a whole other can of worms, but some of these ideas
still generalize.</p>

<p><sup>2</sup>
The template for the master document is available
<a href="https://github.com/dustinvtran/latex-templates"><code class="highlighter-rouge">here</code></a>.</p>

<p><sup>3</sup>
There’s one caveat to Papers. I use it for everything: there are at
least 2,000 papers stored in my account, and with quite a few dense
textbooks.  The application sifts through at least half a dozen
gigabytes, and so it suffers from a few hiccups when
reading/referencing back across many papers. I’m not sure if this is a
bug or just inherent to me exploiting Papers almost <em>too</em> much.</p>

<!--<sup>3</sup>                                                                           -->
<!--Disclaimer: I wrote most of Edward.                                                    -->
<!--I personally benefit from the fact that if                                             -->
<!--something is missing in Edward I can easily add it.                                    -->
<!--[But of course you can (and should) add things too.](http://edwardlib.org/contributing)-->

<ol class="bibliography"><li><span id="neal1994bayesian">Neal, R. M. (1994). <i>Bayesian Learning for Neural Networks</i> (PhD thesis). University of Toronto.</span></li>
<li><span id="pearl2000causality">Pearl, J. (2000). <i>Causality</i>. Cambridge University Press.</span></li>
<li><span id="wainwright2008graphical">Wainwright, M. J., &amp; Jordan, M. I. (2008). Graphical Models, Exponential Families, and Variational Inference. <i>Foundations and Trends in Machine Learning</i>, <i>1</i>(1–2), 1–305.</span></li></ol>

<!--__Failed ideas.__                                                     -->
<!--They go back into master document. Or if there's a large collection of-->
<!--perpheral stuff, they remain as Github repos, but I personally store  -->
<!--them in an `archives/` folder. They're put on hold, and I might-->
<!--revisit them over the years as I spark up new ideas.           -->

<!--__Deployment to Larger Scales.__                                 -->
<!--your mileage will vary, given how you specifically deploy things.-->
<!--different clusters or machines. analysis of how to start placing -->
<!--device configurations in the code.                               -->

<!--+ device configurations                                          -->
<!--+ pretrained models                                              -->
<!--+ xla                                                            -->
<!--+ file readers                                                   -->
<!--+ distributed tensorflow stuff and data management systems       -->

<!--+ redditors and new ml researchers would love it                      -->
<!--+ engineers and non ml experts could read it to understand where we   -->
<!--  come from and how we work, so maybe                                 -->

<!--other things i might mention                                          -->
<!--+ note how write-up and formalism of idea can come before or after    -->
<!--  first iteration of the workflow, depending on whether or kot a forst-->
<!--  iteration is needed to pass a dummy test of if the idea makes sense -->
<!--+ the different ways that you might do research                       -->
<!--+ my personal day to day on how much time i spend reading (relevant   -->
<!--  papers to current research, other papers for breadth of knowledge,  -->
<!--  long term understanding of new subjects), research of               -->
<!--  thinking/writing, coding, meetingd. and also personal management of -->
<!--  ongoing work, such as maitaining and developing edward, and how many-->
<!--  independent projects to tackle at once                              -->
<!--+ code expansion, management of quality, as it grows bigger and bigger-->
</section>
</article>

<!-- Post navigation -->


<!-- Disqus -->


    </div>
    
<script src="/blog/js/katex_init.js"></script>



<footer class="site-footer">
	<p class="text">© 2016 ・ <a class="plain" href="http://dustintran.com">dustintran.com</a>
</p>
</footer>


  </body>
</html>
