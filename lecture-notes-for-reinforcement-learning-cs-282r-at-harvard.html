<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>Lecture notes for Reinforcement learning (CS 282r) | Dustin Tran</title>
	<meta name="description" content="I’ve taken a recent interest in reinforcement learning, particularly regarding Bayesian approaches. There is a taught seminar course at Harvard right now by ...">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-Frame-Options" content="sameorigin">

	<!-- CSS -->
	<link rel="stylesheet" href="/blog/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/blog/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="http://dustintran.com/blog/lecture-notes-for-reinforcement-learning-cs-282r-at-harvard">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="Dustin Tran" href="http://dustintran.com/blog/feed.xml" />

	<!-- Font Awesome -->
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
        <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
	

	<!-- Google Analytics -->
	
	<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-53150914-2', 'auto');
	ga('send', 'pageview');
	</script>
	
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/blog/">
			<img class="avatar" src="/blog/img/photo.png" alt=""/>
		</a>
		
		<h1 class="site-title">
			<a href="/blog/">Dustin Tran</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
                        <li>
				<a class="page-link" href="http://dustintran.com">
					about　
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled -->
			














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






		</ul>
	</nav>
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/blog/')">
    <h1 class="title">Lecture notes for Reinforcement learning (CS 282r)</h1>
    <div style="padding-top:3%;"></div>
    <div class="meta">
      <span class="author">
        By
        
          <a class="author-name" href="http://dustintran.com">Dustin Tran</a>
        
      </span>
      <span class="date">Feb 19, 2015</span>
      <ul>
        














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






      </ul>
    </div>
  </header>
  <section class="post-content"><p>I’ve taken a recent interest in reinforcement learning, particularly regarding Bayesian approaches. There is a taught seminar course at Harvard right now by <a href="http://finale.seas.harvard.edu">Finale Doshi-Velez</a>, a recently hired professor who was a postdoc in Ryan Adam’s <a href="http://hips.seas.harvard.edu">Harvard Intelligent Probabilistic Systems</a> lab and who works on partially observable MDPs. For anyone curious about how the course fares, I’m making my ongoing notes available online:</p>

<ul>
  <li><a href="/blog/assets/cs282r.pdf">CS 282r: Reinforcement learning</a> (Spring 2015)</li>
</ul>

<p>I quite enjoy it so far. As with any seminar course, the structure mostly comprises of reading and discussing seminal papers, and which has led to very interesting discussions. The content itself is quite intriguing as authors have integrated concepts from a variety of fields such as game theory.</p>

<p>I’ve found the experiments and practical applications a bit lackluster however. That is, papers have focused on indicating the effiency of their algorithms through toy problems, which isn’t as appealing as, say, the standard for supervised learning. That is, supervised learning typically benchmarks on a more realistic problem such as classifying categories for text documents or handwritten digits. It will be interesting to see how experimental practices develop as reinforcement learning sees more application in realistic domains.</p>

<p>On another note, I also happen to be taking a course at MIT on cognitive robotics (6.834J) by <a href="https://www.csail.mit.edu/user/816">Brian Williams</a>, which has an interesting overlap in terms of where RL algorithms can be applied. There is an older version of the course archived in the <a href="http://ocw.mit.edu/courses/aeronautics-and-astronautics/16-412j-cognitive-robotics-spring-2005/">MIT OpenCourseWare</a>—no recorded lectures unfortunately. However, there are incredibly useful lecture slides given by the instructor. If given permission, I will release them too.</p>
</section>
</article>

<!-- Post navigation -->


<!-- Disqus -->


    </div>
    
<script src="/blog/js/katex_init.js"></script>



<footer class="site-footer">
	<p class="text">© 2016 ・ <a class="plain" href="http://dustintran.com">dustintran.com</a>
</p>
</footer>


  </body>
</html>
