<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>The generalized method of moments (GMMs), Part I: Introduction | Dustin Tran</title>
	<meta name="description" content="Let  be -dimensional observations (collecting the  covariate within each  response for shorthand) generated from some model with unknown parameters .">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-Frame-Options" content="sameorigin">

	<!-- CSS -->
	<link rel="stylesheet" href="/blog/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/blog/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="http://dustintran.com/blog/the-generalized-method-of-moments-gmms-part-i-introduction">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="Dustin Tran" href="http://dustintran.com/blog/feed.xml" />

	<!-- Font Awesome -->
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
        <script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js"></script>
	

	<!-- Google Analytics -->
	
	<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-53150914-2', 'auto');
	ga('send', 'pageview');
	</script>
	
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/blog/">
			<img class="avatar" src="/blog/img/photo.png" alt=""/>
		</a>
		
		<h1 class="site-title">
			<a href="/blog/">Dustin Tran</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
                        <li>
				<a class="page-link" href="http://dustintran.com">
					about　
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled -->
			














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






		</ul>
	</nav>
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/blog/')">
    <h1 class="title">The generalized method of moments (GMMs), Part I: Introduction</h1>
    <div style="padding-top:3%;"></div>
    <div class="meta">
      <span class="author">
        By
        
          <a class="author-name" href="http://dustintran.com">Dustin Tran</a>
        
      </span>
      <span class="date">Mar 10, 2015</span>
      <ul>
        














<li>
	<a href="https://github.com/dustinvtran" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>





















<li>
	<a href="https://twitter.com/dustinvtran" title="Follow on Twitter">
		<i class="fa fa-fw fa-twitter"></i>
	</a>
</li>






      </ul>
    </div>
  </header>
  <section class="post-content"><p>Let <script type="math/tex">Y_1,\ldots,Y_N</script> be <script type="math/tex">(d+1)</script>-dimensional observations (collecting the <script type="math/tex">X_n\in\mathbb{R}^d</script> covariate within each <script type="math/tex">Y_n\in\mathbb{R}</script> response for shorthand) generated from some model with unknown parameters <script type="math/tex">\theta\in\Theta</script>.</p>

<p><strong>Goal</strong>: Find the “true” parameters <script type="math/tex">\theta^*\in\Theta</script>.</p>

<p><strong>Intuition</strong>: The idea is to find a set of <script type="math/tex">k</script> constraints, or “moments”, involving the parameters <script type="math/tex">\theta</script>. What makes GMMs nice is that you need no information per say about how the model depends on <script type="math/tex">\theta</script>. Certainly they can be used to construct moments (special case: maximum likelihood estimation (MLE)), but one can use, for example, statistical moments (special case: method of moments (MoM)) as the constraints. Analogously, tensor decompositions are used in the case of spectral methods.</p>

<p>More formally, the <script type="math/tex">k</script> <strong>moment conditions</strong> for a vector-valued function <script type="math/tex">g(Y,\cdot):\Theta\to\mathbb{R}^k</script> is</p>

<script type="math/tex; mode=display">m(\theta^*) \equiv \mathbb{E}[g(Y,\theta^*)] = 0_{k\times 1},</script>

<p>where <script type="math/tex">0_{k\times 1}</script> is the <script type="math/tex">k\times 1</script> zero vector.</p>

<p>As we cannot analytically derive the expectation for arbitrary <script type="math/tex">g</script>, we use the sample moments instead:</p>

<script type="math/tex; mode=display">\hat m(\theta) \equiv \frac{1}{N}\sum_{n=1}^N g(Y_n,\theta)</script>

<p>By the Law of Large Numbers, <script type="math/tex">\hat{m}(\theta)\to m(\theta)</script>, so the problem is thus to find the <script type="math/tex">\theta</script> which sets <script type="math/tex">\hat m(\theta)</script> to zero.</p>

<p>Cases:</p>

<ul>
  <li><script type="math/tex">\Theta\supset\mathbb{R}^k</script>, i.e., there are more parameters than moment
conditions: The model is not <a href="http://en.wikipedia.org/wiki/Identifiability">identifiable</a>. This is the standard scenario in ordinary least squares (OLS) when there are more covariates than observations and so no unique set of parameters <script type="math/tex">\theta</script> exist. Solve this by simply constructing more moments!</li>
  <li><script type="math/tex">\Theta=\mathbb{R}^k</script>: There exists a unique solution.</li>
  <li><script type="math/tex">\Theta\subset\mathbb{R}^k</script>,
i.e., there are fewer parameters than moment conditions: The parameters are overspecified and the best we can do is to minimize <script type="math/tex">m(\theta)</script> instead of solve <script type="math/tex">m(\theta)=0</script>.</li>
</ul>

<p>Consider the last scenario: we aim to minimize <script type="math/tex">\hat m(\theta)</script> in some way, say <script type="math/tex">\|\hat m(\theta)\|</script> for some choice of <script type="math/tex">\|\cdot\|</script>. We define the <strong>weighted norm</strong> as</p>

<script type="math/tex; mode=display">\|\hat m(\theta)\|_W^2 \equiv \hat m(\theta)^T W \hat m(\theta),</script>

<p>where <script type="math/tex">W</script> is a positive definite matrix.</p>

<p>The <strong>generalized method of moments</strong> (GMMs) procedure is to find</p>

<script type="math/tex; mode=display">\hat\theta = {arg\ min}_{\theta\in\Theta}
\left(\frac{1}{N}\sum_{n=1}^N g(Y_n,\theta)\right)^T W
\left(\frac{1}{N}\sum_{n=1}^N g(Y_n,\theta)\right)</script>

<p>Note that while the motivation is for <script type="math/tex">\theta\supset\mathbb{R}^k</script>, by the unique solution, this is guaranteed to work for <script type="math/tex">\Theta=\mathbb{R}^k</script> too. Hence it is a <em>generalized</em> method of moments.</p>

<p><strong>Theorem</strong>. Under standard assumptions¹, the estimator <script type="math/tex">\hat\theta</script> is <a href="http://en.wikipedia.org/wiki/Consistent_estimator#Bias_versus_consistency">consistent</a> and <a href="http://en.wikipedia.org/wiki/Asymptotic_distribution">asymptotically normal</a>. Furthermore, if</p>

<script type="math/tex; mode=display">W \propto
\Omega^{-1}\equiv\mathbb{E}[g(Y_n,\theta^*)g(Y_n,\theta^*)^T]^{-1}</script>

<p>then <script type="math/tex">\hat \theta</script> is <a href="http://en.wikipedia.org/wiki/Efficiency_(statistics)">asymptotically optimal</a>, i.e., achieves the Cramér-Rao lower bound.</p>

<p>Note that <script type="math/tex">\Omega</script> is the covariance matrix of <script type="math/tex">g(Y_n,\theta^*)</script> and <script type="math/tex">\Omega^{-1}</script> the precision. Thus the GMM weights the parameters of the estimator <script type="math/tex">\hat\theta</script> depending on how much “error” remains in <script type="math/tex">g(Y,\cdot)</script> per parameter of <script type="math/tex">\theta^*</script> (that is, how far away <script type="math/tex">g(Y,\cdot)</script> is from 0).</p>

<p>I haven’t seen anyone make this remark before, but the GMM estimator can also be viewed as minimizing a log-normal quantity. Recall that the multivariate normal distribution is proportional to</p>

<script type="math/tex; mode=display">\exp\Big((Y_n-\mu)^T\Sigma^{-1}(Y_n-\mu)\Big)</script>

<p>Setting <script type="math/tex">g(Y_n,\theta)\equiv Y_n-\mu</script>, <script type="math/tex">W\equiv\Sigma</script>, and taking the log, this is exactly the expression for the GMM! By the asymptotic normality, this explains why would want to set <script type="math/tex">W\equiv\Sigma</script> in order to achieve statistical efficiency.</p>

<p>¹ The standard assumptions can be found in [1]. In practice they will almost always be satisfied, e.g., compact parameter space, <script type="math/tex">g</script> is continuously differentiable in a neighborhood of <script type="math/tex">\theta^*</script>, output of <script type="math/tex">g</script> is never infinite, etc.</p>

<h2 id="references">References</h2>
<p>[1] Alastair Hall. <em>Generalized Method of Moments (Advanced Texts in Econometrics)</em>. Oxford University Press, 2005.</p>
</section>
</article>

<!-- Post navigation -->


<!-- Disqus -->


    </div>
    
<script src="/blog/js/katex_init.js"></script>



<footer class="site-footer">
	<p class="text">© 2016 ・ <a class="plain" href="http://dustintran.com">dustintran.com</a>
</p>
</footer>


  </body>
</html>
